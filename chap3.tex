\chapter{Collision Supported Path Planning}
In this chapter, we will look at a number of algorithms we propose for finding paths that are tolerant of collisions. These approaches will favor different strategies for finding these paths such as finding optimal paths versus computation time (or a combination of these). The discussion on algorithm performance will be addressed in the following chapter. The different algorithms that will be discussed are as follows.

\begin{enumerate}
\item Obstacle ignorant Bi-directional RRT
\item Bi-directional RRT with greedy object removal
\item Bi-directional RRT with probabilistic object removal
\item Repeated Bi-directional RRT with object removal
\item Bi-directional RRT object with removal and adding
\end{enumerate}

Note that all of the RRT variants are actually bi-RRT variants but for conciseness we will just refer to them as RRT variants.

\section{Obstacle Ignorant RRTs}
In this section we will describe a simple alternative to the traditional RRT that enables it to find paths that tolerate collisions. In particular this algorithm favors finding some path very quickly and does not prioritize minimizing the total path cover. We will shorthand this planner as OIRRT (obstacle ignorant RRT).

\subsection{OIRRT Details}
The OIRRT is in essence a simpler version of the bi-directional RRT. In fact, the implementation is nearly identical. Consult the description of the RRT available \todo{add ref}. We maintain two trees as Lavalle proposed while adding goal biasing for both trees. The only difference occurs in the tree growing phase where we will add the sampled node to its respective tree regardless of any collisions. The OIRRT is thus ignorant of any obstacles in the world until the two trees meet at which point the cover of the trajectory can be returned to the higher level planner. OIRRTs can be thought of as upfront constraint removal -- that is anytime a constraint would be violated, we simply remove them as we did in the MCR algorithm. 

\subsection{OIRRT benefits and disadvantages}
A clear deficiency of the OIRRT is that it likely will not find a minimum cover path. In fact it likely will return a path that is not "close" to the optimal cover path either, as it merely explores the space randomly and returns the first full path it finds.

This algorithm has some interesting properties, however. If we were interested in a path from the start to the goal, we could simple interpolate the straight path from the $s \rightarrow g$. However by introducing the randomness from sampling we enable the potential to explore space between these configurations potentially circumventing obstacles in the direct trajectory; while the OIRRT does not attempt to determine problematic obstacles, it still demonstrates a potential to find some good paths.

\section{Iterative Obstacle Removing RRTs}
This section explores the concept of iterative constraint removal via RRTs (IOR-RRT). The previous section on OIRRTs were immediate on constraint removal. As a result these constraint removals were largely uninformed -- specifically they were informed from a single data point (a collision with this constraint in tree growth). We propose two variants of iterative constraint removal that accumulate information of the state of the world and then proceed to perform constraint removal.

\subsection{Details}
This family of algorithms proceeds similarly to the bidirectional RRT algorithm. The general algorithm is outlined below.
\todo{Figure out spacing of function arguments that are in math mode vs not}
{\singlespacing{
\begin{algorithm}[t]
\begin{algorithmic}[1]
\Function{Iterative Obstacle Removing RRT}{$q_s,q_g$}
    \State counts $\gets$ \{\}
    \State permitted $\gets$ set()
    \State $T_a$.init($q_s$);
    \State $T_b$.init($q_g$);
    \For{$k$ = 1 to $K$}
        \If {$k$ \% $f$ = 0}
            \State \Call{Remove Constraint}{counts,permitted,$memory$};
        \EndIf
        \State $q_s \gets$ \Call{Random Sample}{};
        \State $q_{near} \gets$ \Call{Nearest}{$T_a, q_s$};
        \State success,$q_n \gets$ \Call{Attempt Extend}{$q_{near}, q_s$,counts,permitted};
        \If{success AND $q_{near} \ne q_n$}
            \State $T_a$.add\_vertex($q_n$);
            \State $T_a$.add\_edge($q_{near}, q_n$);
            \State $q_{near}' \gets$ \Call{Nearest}{$T_b, q_n$};
            \State $success', q_n' \gets$ \Call{Attempt Extend}{$q_{near}', q_n$,permitted};
            \If{success' AND $q_{near}' \ne q_n'$}
                \State $T_b$.add\_vertex($q_n'$);
                \State $T_b$.add\_edge($q_{near}', q_n'$);
            \EndIf
            \If{$q_n = q_n'$}
                \State Return SOLUTION;
            \EndIf
        \EndIf
        \If{$|T_a| > |T_b|$}
            \State \Call{SWAP}{$T_a, T_b$};
        \EndIf
    \EndFor
    \State Return FAILURE;
\EndFunction

\Function{Attempt Extend}{$q_1, q_2$,counts,permitted}
    \For{$q \in$ \Call{Interpolate}{$q_1, q_2$}
        \State viols $\gets$ \Call{Collisions}{$q$};
        \If{viols $\not\subseteq$ permitted}
            \For{viol $\in$ viols}
                \If{viol $\not\in$ permitted}
                    \State counts[viol] += 1
                \EndIf
            \EndFor
            \State Return FAILURE, NONE
        \EndIf
    \EndFor
    \State Return SUCCESS,$q_2$
\EndFunction

\Function{Remove Constraint}{counts, permitted, $memory$}
    \State $c \gets$ \Call{Removal Strategy}{counts, permitted};
    \State permitted.add($c$);
    \For{viol $\in$ counts}
        \State counts[viol] $\ast= memory$;
    \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}
}}

The algorithm attempts to grow a bi-directional RRT as the original algorithm does. A significant difference is upon colliding with an obstacle on interpolation between two configurations, the algorithm stores memory of this collision. Once a collision is found and its presence marked, the extend immediately fails and we return to the growth loop of the RRT. 

This type of constraint removal introduces a new parameter $f$ that governs how often we will choose a constraint to ignore. In turn this affects the number of constraint violations that can be recorded before selecting an obstacle to ignore. If the number of iterations that the iterative obstacle removal RRT is bounded by $K$, then at most $c=\frac{K}{f}$ obstacles will be removed. If our motion planning problem is unsolvable with ignoring $c$ constraints, then this algorithm can never find a solution. Thus fragility can be a problem in worlds where setting an upper bound on the number of obstacles that need to be removed can be determined.

\subsection{Collision History as an Indicator to Removal Importance}
The family of iterative obstacle removal RRTs are designed around finding a path quickly while attempting to mitigate the number of obstacles that must be removed to find such a path. Because we are interested in avoiding excessive obstacle removal, we need a signal on the importance of an obstacle in this goal. Using the collision history in practice works as this good signal. Intuitively, the more frequently an obstacle is run into, the more likely a path will be found by removing this obstacle.

While removing obstacles that are collided with the most helps find a path, it is not the case that an obstacle must be removed to find a path. In worlds that have solution with small tolerance for movement in the surrounding swept volume, it can be difficult for a bi-directional RRT to find this path ($P$). Given enough time, the bi-directional RRT can find $P$, while an iterative obstacle removal RRT will simply select an obstacle to remove allowing for more tolerance in the region surrounding $P$.

\subsection{Constraint Removal Strategy}
Every $REMOVAL\_FREQUENCY$ iterations we select a new constraint that can be violated as needed. Below we propose two strategies for choosing this constraint: greedy removal and probabilistic removal.
\subsubsection{Greedy Removal}
This method of removal chooses the constraint to remove that is empirically determined to be a constraint of importance. Specifically, let the mapping of obstacles to collision counts be noted as pairs of $(o, c_o)$. Each of these obstacles has a weight $w_o$. We then select the constraint using the formula:

$$\argmax\limits_{o \in O} \frac{c_o}{w_o}$$

This selects the constraint that has the highest importance score -- the collision counts scaled by the inverse of the weight of the obstacle. Thus a heavy obstacle requires more collisions to be selected while a lighter obstacle needs less. This method encodes the difficulty associated with moving high weight obstacles as well as pushes the algorithm to lighter obstacles in the goal of approximating the true MCR solution.


\subsubsection{Probabilistic Removal}
The probabilistic removal method introduces an additional layer of randomness in the iterative obstacle removing family of RRTs. Unlike the greedy removal strategy, the probabilistic removal strategy selects the constraint to remove using the distribution generated over the importance scores. Specifically,
$$o_{remove} \sim \frac{1}{\sum_{i=1}^k \frac{c_i}{w_1}}[\frac{c_1}{w_1}, \frac{c_2}{w_2},\ldots, \frac{c_k}{w_k}]$$

This method allows the motion planner to select obstacles outside those that are deemed the most important. Instead we can sample on the importance in the pursuit of being more robust to adversarial worlds where the obstacles that appear promising for removal may actually be either useless or result in higher total covers than is necessary. 

\subsection{Notion of Memory Factor}


\section{Repeated Iterative Obstacle Removal RRTs}

\section{Search Informed Iterative Obstacle Removal RRTs}

\subsection{Repeated Single Search Informed IOR-RRT}

\subsection{Repeated Search Informed Single IOR-RRT}





