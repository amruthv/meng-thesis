%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction} \label{intro}
Robotic systems are becoming increasingly commercial (e.g. the Roomba, self driving cars) yet the field of robotics is far from having completely autonomous robots. There is still room for improvement before they can handle complex tasks autonomously. A robotic system excels when using it is easier than having a human perform the task or even monitor the robot's performance.

Having a robot identify a series of actions to perform to accomplish a goal is a challenging task. The robot requires a good representation of the dynamics of the world and of itself as well as a method for translating any decisions the robot decides to make into physical actions in the world. Other difficulty can lay in the actual search problem of identifying the sequence of actions to take that would result in the desired outcome. This can be further complicated with uncertainty in the world as well as error in actual execution of any actions.

\section{Planners} \label{intro:planners}
The component of a robot responsible for determining the actions to take is its planner. These invisible systems are used to make sense of the task to be performed. Planners use two types of planning: task and motion planning. 

A task planning problem is often fomulated using the language PDDL \todo{cite PDDL} formulated as a triple ($A, s_0, g$). A specifies all actions that can be taken along with their corresponding preconditions and postconditions. The task planning problem looks for a series of actions that can take the initial state $s_0$ to a final state $s_{n}$ that contains all of the propositions in $g$. 

A motion planning problem is a continuous problem specified by the configuration space $C$, a start configuration $s$ and a goal configuration $g$ for $s,g \in C$. The planning problem is successful if there exists a path from $s$ to $g$ that is not in violation with any of the obstacles in the space in which the robot operates. \todo{What is the exact name for this} 

Planners use these two types of planning to discover a complete plan. Some planners integrate discrete task planning with continuous motion planning. Many of these techniques use motion planners to verify plans found by task planners. Other techniques more closely intertwine the two planning strategies such each planning component can influence the other. 

\section{A Need for Collision Tolerant Motion Planning} \label{intro:collisiontolerant}
Many recent planning methods rely on being able to identify avenues of making motion planning problems feasible. A method of doing this is to find a path $p:s \rightarrow g$ that tolerates collisions. Evaluating collisions along $p$ determines a path that would be collision-free if these collisions were resolved (e.g. moved to a different location in the world). Thus, non-traditional motion planning that can find paths that tolerate collisions is highly valuable. 

Two such planners that require a method of identifying failure reasons are Srivastava's planning using an interface layer and Kaelbling and Lozano-P\'{e}rez's BHPN \todo{cite Srivastava} \todo{cite pre-image}. 

Srivastava's planner is a forward-searching planner that first finds a task plan for the given planning problem using symbolic references. The interface layer then searches through all assignments of the symbolic references and collision-free motion plans that satisfy the chosen assignments. If no such complete instantiation of poses exists that has a error-free motion plan, the original task plan cannot be resolved into a motion plan. Instead it then tries the first pose instantiation and uses a motion planner that allows all non-permanent collisions to determine the failure reasons. These reasons are stored as state to be reused in a new task planning problem on the updated state from which the original planning procedure can resume. 

The hierarchichal planner designed by Kaelbling and Lozano-P\'{e}rez uses pre-image backchaining (also known as goal regression) to solve planning problems. The planner assumes that the robot is able to perform actions to modify the poses of a subset of the objects in the world but only individually. The regression procedure breaks down a planning problem with obstacles to iteratively considering the impact of each obstacle's pose on the pre-image of the goal under the actions of a candidate plan. Each pose can be found by finding a pose of the given obstacle that does not overlap with the swept volume of a path that allows collisions (found in some manner by a motion planner). This mechanism of finding a pose is used regularly throughout the planning procedure so it must be quick.

In both of these different planners, there is one fundamental need - a good method of finding motion paths that are tolerant of collisions, but ideally only tolerate collisions when necessary. A bad motion planner could introduce performance penalties if it was overly-aggressive in tolerating collisions with obstacles. However, being overly defensive to collisions can result in high performance penalties if the planner tries excessively to find a collision-free path when one does not exist. 

\section{Research Problem Statement} \label{intro:statement}
The particular problem we will be addressing in the paper is the constraint removal problem for holonomic systems. A more specific variant of this problem is the Minimum Constraint Removal (MCR) problem as formulated by Kris Hauser \cite{hauser:mcr}. The problem operates on an established graph that has vertices $V$ corresponding to different robot configurations. The edges of the graph $E$ correspond to trajectories between these configurations. 
\newline

\noindent
{\bf{Discrete-MCR Problem:}}\\
Input: Graph $G = (V,E)$, Cover Function $C[v]$, $s,g \in V$  \\
Output: $S^{*}_g$
\newline

The MCR problem also specifies a cover function to identify collisions at a configuration. Specifically, the cover $C[q]$ of a configuration $q$ is the subset of of obstacles \{1,2,3,...,m\} with which the robot collides with if placed at the configuration $q$. Let $S_q$ be the cover (possibly optimal) of the path from $s \rightarrow q$. $S^{*}$ is the answer the the MCR problem, that is the minimum number of obstacles that can be in collision with the robot while following some path p[t], t:[0,1], from a start configuration $s$ to a goal configuration $g$. Thus $S^{*} = S^{*}_g$. $S^{*}$ is defined as the minimum constraint removal and is the cover along this minimum collision path. 

This problem falls into the class of NP-hard problems (the proof can be seen in Hauser's paper). Because solving the MCR problem is impractical, we are interested in algorithms that handle the most common case, worlds where collision-free paths exist, particularly efficiently. That is, it should not introduce unecessary collisions. It must be able to find paths that contain collisions in the less frequent world where a collision-free path does not exist, but be selective to approximate the real MCR solution.

In the rest of this paper we will focus on a number of algorithms that can be used to find paths that support constraint violations. These algorthms are not minimum constraint removal solvers; these algorithms instead find some path tolerant of constraint violations and are ideally close to the true MCR solution. Each of these algorithms will offer different tradeoffs in running time and quality of paths as measured by collisions.
