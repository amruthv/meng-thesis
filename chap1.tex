%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction} \label{intro}
Robotic systems are becoming increasingly commercial yet the field of robotics is far from having completely autonomous robots. There is still room for improvement before they can independently handle complex tasks. A robotic system excels when using one is easier than having a human perform the task or monitor the robot's performance.

Having a robot identify a series of actions to perform to accomplish a goal is challenging. The robot requires a good representation of the dynamics of the world and of itself. It also needs a method for translating any decisions the robot decides to make into physical actions in the world. Other difficulty can lay in the actual search problem of identifying the sequence of actions to take that would result in the desired outcome. This can be further complicated with uncertainty in the world as well as error in actual execution of any actions.

\section{Planners} \label{intro:planners}
The component of a robot responsible for determining the actions to take is its planner. These invisible systems are used to make sense of the task to be performed. Planners use two types of planning: task planning and motion planning. 

A task planning problem is often fomulated using the language PDDL as a triple ($A, s_0, g$) \cite{srivastava:interface}. $A$ specifies all actions that can be taken along with their corresponding preconditions and postconditions. The task planning problem looks for a series of actions that can take the initial state $s_0$ to a final state $s_{n}$ that contains all of the propositions in $g$.

A motion planning problem is a continuous problem specified by the configuration space $C$, a start configuration $s$, and a goal configuration $g$, for $s,g \in C$. The planning problem is feasible if there exists a path from $s$ to $g$ that is not in violation with any of the obstacles.

Planners use these two planning types to find a complete plan. Some planners integrate discrete task planning with continuous motion planning. Many of these techniques use motion planners to verify plans found by task planners. Other techniques more closely intertwine the two planning strategies such that each planning component can influence the other. 

\section{A Need for Collision Tolerant Motion Planning} \label{intro:collisiontolerant}
Many recent planning methods rely on being able to identify avenues of making motion planning problems feasible. A method of doing this is to find a path $p:s \rightarrow g$ that tolerates collisions. Evaluating collisions along $p$ determines a path that would be collision-free if these obstacles were moved. Thus, non-traditional motion planning that can find paths tolerant of collisions is highly valuable. 

Two such planners that require a method of identifying failure reasons are Srivastava's planner with an interface layer and Kaelbling and Lozano-P\'{e}rez's BHPN \cite{kaelbling_tlp:preimage} \cite{srivastava:interface}. 

Srivastava's planner is a forward-searching planner that first finds a task plan for the given planning problem using symbolic references. The interface layer then searches through all assignments of the symbolic references and collision-free motion plans that satisfy the chosen assignments. If no such complete instantiation of poses exists that has a error-free motion plan, the original task plan cannot be resolved into a motion plan. The interface layer then tries the first pose instantiation and uses a motion planner that allows all non-permanent collisions to determine the failure reasons. These reasons are stored as state to be reused in a new task planning problem on the updated state from which the original planning procedure can resume. 

The hierarchichal planner designed by Kaelbling and Lozano-P\'{e}rez uses pre-image backchaining (also known as goal regression) to solve planning problems. They assume the robot is able to manipulate the poses of a subset of the objects in the world individually. The regression procedure breaks down a planning problem with obstacles to iteratively considering the impact of each obstacle's pose on the pre-image of the goal under the actions of a candidate plan. Each pose is found by identifying a pose via a motion planner that allows the robot to reach a particular configuration. This mechanism of finding a pose is used regularly throughout the planning procedure so it must be quick.

In both of these different planners, there is one fundamental need - a method of finding motion paths that are tolerant of collisions, but ideally only tolerate collisions when necessary. A bad motion planner could introduce performance penalties if it was overly-aggressive in tolerating collisions with obstacles. However, being overly defensive to collisions can result in high performance penalties if the planner tries excessively to find a collision-free path when one does not exist. 

\section{Research Problem Statement} \label{intro:statement}
The particular problem we address in this paper is the constraint removal problem for holonomic systems. A more specific variant of this problem is the Minimum Constraint Removal (MCR) problem as formulated by Kris Hauser \cite{hauser:mcr}. The problem operates on an established graph that has vertices $V$ corresponding to different robot configurations. The edges of the graph $E$ correspond to trajectories between these configurations. 

\begin{mdframed}
{\bf{Discrete-MCR Problem:}}\\
Input: Graph $G = (V,E)$, Cover Function $C[v]$, $s,g \in V$ \\
Output: $S^{*}_g$
\end{mdframed}

The MCR problem also specifies a cover function to identify collisions at a configuration. Specifically, the cover $C[q]$ of a configuration $q$ is the subset of obstacles \{1,2,3,...,m\} the robot collides with if placed at the configuration $q$. Let $S_q$ be the cover (possibly optimal) of a path from the start configuration $s$ to the goal configuration $q$. Note that there can be many $S_q$ for a particular $q$ since there are many paths $s \rightarrow q$. A subset of these will have the lowest cover, which we denote $S^{*}_q$. The answer to the MCR problem is $S^{*}$, that is the minimum number of obstacles that can be in collision with the robot while following some path $s \rightarrow g$. Thus $S^{*} = S^{*}_g$. In this paper we will use "constraint removal" synonymously with "obstacle removal" as these obstacles correspond to constraints that the robot must respect to be collision-free.

This problem falls into the class of NP-hard problems (the proof can be seen in Hauser's paper). Because solving the MCR problem optimally is impractical, we need an algorithm that works well in practice; it should handle the most common case, worlds where collision-free paths exist, particularly efficiently. That is, it should not introduce unnecessary collisions. It must also be able to find paths that contain collisions in the less frequent world where a collision-free path does not exist, but be selective to approximate the exact MCR solution.

In the rest of this paper we will focus on a number of algorithms that can be used to find paths that support constraint violations. These algorthms are not minimum constraint removal solvers; these algorithms instead find some path tolerant of constraint violations with cover $S_g$ that we want to be close to $S^{*}$. Each of these algorithms will offer different tradeoffs in running time and quality of paths as measured by collisions. 
